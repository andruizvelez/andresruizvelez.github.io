<!--
## Description: Guides you through analyzing an A/B test or experiment, capturing the hypothesis, how the experiment was run, results and significance, and the conclusions or next actions.
## Usage Note: Use after running an experiment to interpret the outcomes. Be ready to provide the hypothesis, what was measured, and the results for each variant. The prompt will structure your analysis and extract insights.
## Instructions: The AI will prompt for key details: your hypothesis, how the experiment was set up (sample sizes, duration), the results of each variant, and any surprising findings. Then it will help articulate whether the hypothesis was supported, what you learned, and what to do next. The output is a mini report you can share with your team.
## Attribution: Follows industry best practices for A/B test post-analysis as advocated in Lean Startup and data-driven product development literature.
-->

## Experiment Analysis

**Hypothesis:**  
- [State the hypothesis being tested. Example: "We believe that changing the call-to-action button color from green to red will increase signup rate by 10%."]

**Experiment Setup:**  
- **Variants:** [Describe what was different: e.g., Control (green button) vs Variant (red button)].  
- **Sample & Duration:** [How many users in each group and how long the test ran].  
- **Metrics Tracked:** [The primary metric (e.g., signup conversion %) and any secondary metrics observed].

**Results:**  
- **Control:** [Metric results for control, e.g., "Signup rate = 8.5%"].  
- **Variant:** [Metric results for variant, e.g., "Signup rate = 9.3%"].  
- **Statistical Significance:** [If calculated, e.g., "95% confidence the variant is better" or "not statistically significant"].  
- **Other Observations:** [Any notable impacts on secondary metrics or user segments].

**Analysis:**  
- [Was the hypothesis supported? e.g., "Yes, variant increased signups as expected" or "No, difference was not significant"].  
- [Possible reasons for the outcome: e.g., "Red color may have drawn more attention" or "Users might not be sensitive to button color"].  
- [Any anomalies: e.g., "Variant improved conversion on desktop but not on mobile"].

**Learnings:**  
- [Key takeaways: e.g., "Small UI changes can impact user behavior" or "We learned our hypothesis was wrong about color, need to test messaging instead"].  
- [Insights into user behavior or preferences gleaned from the experiment].

**Next Steps:**  
- [Decisions: e.g., "Roll out the red button to all users" or "Do not implement change since no improvement"].  
- [Follow-up experiments: e.g., "Test button wording next" or "Try a bigger design change since color alone had minor effect"].  
- [Any additional action: "Share results with design team, update our design guidelines", etc.].
